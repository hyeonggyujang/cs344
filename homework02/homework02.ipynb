{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1. Below is a simple implementation of Paul Graham's spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'that': 0, 'not': 0, 'like': 0.3333333333333333, 'am': 0.99, 'eggs': 0.01, 'ham': 0.01, 'I': 0.99, 'i': 0.01, 'spam': 0.99, 'spamiam': 0, 'do': 0.3333333333333333, 'green': 0.01, 'and': 0.01}\n",
      "It's a spam.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function takes in the sample spam and non-spam dictionaries and the list of unique words\n",
    "to output a dictionary of each word's prior probability for the posterior calculation later.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_prob_dict(spam_dict, ham_dict, wordList, ngood, nbad):\n",
    "    dict_prob = {}\n",
    "    for item in wordList:\n",
    "        if item in ham_dict.keys():\n",
    "            g = 2 * ham_dict[item]\n",
    "        else:\n",
    "            g = 0\n",
    "        if item in spam_dict.keys():\n",
    "            b = spam_dict[item]\n",
    "        else:\n",
    "            b = 0\n",
    "        if g + b > 1:\n",
    "            prob = max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b / nbad))))\n",
    "        else:\n",
    "            prob = 0\n",
    "        dict_prob[item] = prob\n",
    "    return dict_prob\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function takes in the sample spam and non-spam token lists \n",
    "to create the dictionaries of each unique word counts,\n",
    "and feed it into make_prob_dict function.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_filter(spam_corpus, ham_corpus):\n",
    "    dict_spam_corpus = {}\n",
    "    dict_ham_corpus = {}\n",
    "    words = []\n",
    "\n",
    "    nbad = 0\n",
    "    for corpus in spam_corpus:\n",
    "        nbad += 1\n",
    "        for word in corpus:\n",
    "            if word not in words:\n",
    "                words.append(word)\n",
    "            if word not in dict_spam_corpus.keys():\n",
    "                dict_spam_corpus[word] = 1\n",
    "            else:\n",
    "                dict_spam_corpus[word] += 1\n",
    "\n",
    "    ngood = 0\n",
    "    for corpus in ham_corpus:\n",
    "        ngood += 1\n",
    "        for word in corpus:\n",
    "            if word not in words:\n",
    "                words.append(word)\n",
    "            if word not in dict_ham_corpus.keys():\n",
    "                dict_ham_corpus[word] = 1\n",
    "            else:\n",
    "                dict_ham_corpus[word] += 1\n",
    "\n",
    "    return make_prob_dict(dict_spam_corpus, dict_ham_corpus, words, ngood, nbad)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This function takes in the corpus to be tested and the dictionary of prior probabilities, \n",
    "to output binary value indicating whether the input corpus is a spam or not.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def to_spam_or_not_to_spam(corpus, filt):\n",
    "    for word in corpus:\n",
    "        if word not in filt.keys():\n",
    "            filt[word] = 0.4\n",
    "    kernel = 1\n",
    "    complement_prob = 1\n",
    "    for word in corpus:\n",
    "        kernel *= filt[word]\n",
    "        complement_prob *= 1 - filt[word]\n",
    "    marginal = kernel + complement_prob\n",
    "    final = kernel / marginal\n",
    "    if final > 0.9:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# sample tokens\n",
    "bad_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "good_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "# the tokens to be tested\n",
    "sample_corpus = [\"I\", \"am\", \"spam\"]\n",
    "\n",
    "# create the filter (dictionary of prior probabilities)\n",
    "hash_filter = create_filter(bad_corpus, good_corpus)\n",
    "\n",
    "print(hash_filter)\n",
    "\n",
    "# test the corpus of interest\n",
    "if to_spam_or_not_to_spam(sample_corpus, hash_filter):\n",
    "    print(\"It's a spam.\")\n",
    "else:\n",
    "    print(\"It's not a spam.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Graham argues that this is a Baysian approach to SPAM. What makes it Bayesian?\n",
    "A: When analyzing the sample_corpus, the Bayesian statistics method is used to evaluate the probability of the given corpus is a spam or not. The prior probability is caculated in hash_filter. The posterior is normalized at \"final\" step of the to_spam_or_not_to_spam(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. The implementation of Fig. 14.12a is as follow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'probability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c6ef1a1d5edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumeration_ask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Utility variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# From AIMA code (probability.py) - Fig. 14.12a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'probability'"
     ]
    }
   ],
   "source": [
    "from probability import BayesNet, enumeration_ask\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "# From AIMA code (probability.py) - Fig. 14.12a\n",
    "bayes_net = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.5}),\n",
    "    ('Rain', 'Cloudy', {T: 0.8, F: 0.2}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of independent values in the full joint probability distribution for this domain is 2^4 = 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of independent values in the Bayesian network for this domain is 9. (Just counting up the values given in the Fig. 14.12a.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enumeration_ask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-517b8b491196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumeration_ask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cloudy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# ii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ii.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumeration_ask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sprinkler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCloudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_approx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# iii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enumeration_ask' is not defined"
     ]
    }
   ],
   "source": [
    "# i\n",
    "print(\"i.\", enumeration_ask('Cloudy', dict(), bayes_net).show_approx())\n",
    "# ii\n",
    "print(\"ii.\", enumeration_ask('Sprinkler', dict(Cloudy=T), bayes_net).show_approx())\n",
    "# iii\n",
    "print(\"iii.\", enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=T), bayes_net).show_approx())\n",
    "# iv\n",
    "print(\"iv.\", enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), bayes_net).show_approx())\n",
    "# v\n",
    "print(\"v.\", enumeration_ask('Cloudy', dict(WetGrass=F), bayes_net).show_approx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
